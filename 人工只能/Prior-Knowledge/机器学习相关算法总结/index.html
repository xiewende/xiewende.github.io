<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>机器学习相关算法总结 | sevenboy</title><meta name="keywords" content="bagging, boosting, 决策树, GBDT, XGBoost, K-Means"><meta name="author" content="sevenboy"><meta name="copyright" content="sevenboy"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="这是常用机器学习的简单总结">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习相关算法总结">
<meta property="og:url" content="https://sevenboy.online/%E4%BA%BA%E5%B7%A5%E5%8F%AA%E8%83%BD/Prior-Knowledge/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/index.html">
<meta property="og:site_name" content="sevenboy">
<meta property="og:description" content="这是常用机器学习的简单总结">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/image.png">
<meta property="article:published_time" content="2023-08-22T16:25:16.000Z">
<meta property="article:modified_time" content="2023-09-18T16:16:38.531Z">
<meta property="article:author" content="sevenboy">
<meta property="article:tag" content="人工只能">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="machine learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/image.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://sevenboy.online/%E4%BA%BA%E5%B7%A5%E5%8F%AA%E8%83%BD/Prior-Knowledge/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习相关算法总结',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2023-09-19 00:16:38'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/image/myself.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">27</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">31</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 家</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/image.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">sevenboy</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 家</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习相关算法总结</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-08-22T16:25:16.000Z" title="发表于 2023-08-23 00:25:16">2023-08-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-09-18T16:16:38.531Z" title="更新于 2023-09-19 00:16:38">2023-09-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E5%8F%AA%E8%83%BD/">人工只能</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E5%8F%AA%E8%83%BD/Prior-Knowledge/">Prior Knowledge</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">18.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>65分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习相关算法总结"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h4 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h4><p>集成学习通过训练多个分类器，然后将其组合起来，从而达到更好的预测性能，提高分类器的泛化能力。</p>
<p>Baggging 和Boosting都是模型融合的方法，可以将弱分类器融合之后形成一个强分类器，而且融合之后的效果会比最好的弱分类器更好。</p>
<p>目前集成学习主要有三个主要框架：bagging，boosting，stacking。</p>
<p><strong>偏差：训练到的模型与真实标签之间的区别。</strong></p>
<p><strong>方差：每次学习的模型之间差别有多大。</strong></p>
<p><strong>偏差指的是算法的期望预测与真实值之间的偏差程度，反映了模型本身的拟合能力；</strong></p>
<p><strong>方差度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动所导致的影响。</strong></p>
<h5 id="bagging套袋法"><a href="#bagging套袋法" class="headerlink" title="bagging套袋法"></a>bagging套袋法</h5><p>bagging是并行集成学习方法的最著名代表，其算法过程如下：</p>
<ul>
<li><p>从原始样本集中抽取训练集。每轮从原始样本集中使用Bootstraping的方法抽取n个训练样本（在训练集中，有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中）。共进行k轮抽取，得到k个训练集。（k个训练集之间是相互独立的）</p>
</li>
<li><p>每次使用一个训练集得到一个模型，k个训练集共得到k个模型。（注：这里并没有具体的分类算法或回归方法，我们可以根据具体问题采用不同的分类或回归方法，如决策树、感知器等）</p>
</li>
<li><p>对分类问题：将上步得到的k个模型采用投票的方式得到分类结果；对回归问题，计算上述模型的均值作为最后的结果。（所有模型的重要性相同）</p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/1.png" alt=""></p>
</li>
</ul>
<h5 id="boosting提升法"><a href="#boosting提升法" class="headerlink" title="boosting提升法"></a>boosting提升法</h5><p>大多数的提升方法都是改变训练数据的概率分布（训练数据中的各个数据点的权值分布），调用弱学习算法得到一个弱分类器，再改变训练数据的概率分布，再调用弱学习算法得到一个弱分类器，如此反复，得到一系列弱分类器。<strong>两个问题？</strong></p>
<ol>
<li>是在每一轮如何改变训练数据的概率分布。</li>
<li>是如何将多个弱分类器组合成一个强分类器。</li>
</ol>
<p><strong>关于第一个问题</strong>，AdaBoosting方式每次使用的是全部的样本，每轮训练改变样本的权重。下一轮训练的目标是找到一个函数f 来拟合上一轮的残差。当残差足够小或者达到设置的最大迭代次数则停止。</p>
<p><strong>至于第二个问题</strong>，采取加权多数表决的方法。Boosting会减小在上一轮训练正确的样本的权重，增大错误样本的权重。（对的残差小，错的残差大）梯度提升的Boosting方式是使用代价函数对上一轮训练出的模型函数f的偏导来拟合残差。</p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/2.png" style="zoom:33%;" /></p>
<h5 id="bagging和boosting区别"><a href="#bagging和boosting区别" class="headerlink" title="bagging和boosting区别"></a>bagging和boosting区别</h5><p><strong>Bagging是减少方差variance，而Boosting是减少偏差bias</strong></p>
<p><strong>（1）样本选择上：</strong></p>
<ul>
<li><p>Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。</p>
</li>
<li><p>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。</p>
</li>
</ul>
<p><strong>（2）样例权重：</strong></p>
<ul>
<li><p>Bagging：使用均匀取样，每个样例的权重相等。</p>
</li>
<li><p>Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。</p>
</li>
</ul>
<p><strong>（3）预测函数：</strong></p>
<ul>
<li><p>Bagging：所有预测函数的权重相等。</p>
</li>
<li><p>Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。</p>
</li>
</ul>
<p><strong>（4）并行计算：</strong></p>
<ul>
<li><p>Bagging：各个预测函数可以并行生成。</p>
</li>
<li><p>Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。</p>
</li>
</ul>
<h5 id="stacking模型融合"><a href="#stacking模型融合" class="headerlink" title="stacking模型融合"></a>stacking模型融合</h5><p><strong>stacking 就是当用初始训练数据学习出若干个基学习器后，将这几个学习器的预测结果作为新的训练集，来学习一个新的学习器。</strong></p>
<p><strong>Bagging是减少方差variance和偏差bias。Stacking既减少方差又减少偏差。</strong></p>
<p><strong>Bagging是尽可能的提高模型的随机性，使得模型之间没有强相关性，以此降低融合的方差。</strong></p>
<p><strong>Boosting是不断递进的优化每个分类器，逐步减少偏差，各分类器直接具有强相关性，因此不会降低方差。</strong></p>
<h4 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h4><p>什么是决策树呢？决策树是一种监督学习方法，既可以用来处理分类问题也可以处理回归问题。</p>
<p>决策树是一个<strong>有监督分类模型</strong>，本质是选择一个最大信息增益的特征值进行输的分割，直到达到结束条件或叶子节点纯度达到阈值。</p>
<h5 id="ID3算法（信息增益）"><a href="#ID3算法（信息增益）" class="headerlink" title="ID3算法（信息增益）"></a>ID3算法（信息增益）</h5><ul>
<li><p>思想：ID3使用信息增益作为特征选择的度量，使用自顶向下的贪心算法遍历决策树空间。</p>
<ul>
<li>（1）计算数据集合的<strong>信息熵</strong>，以及各个特征的<strong>条件熵</strong>，最后计算<strong>信息增益</strong>，选择信息增益最大的作为本次划分的节点</li>
<li>（2）删除上一步使用的特征。更新各个分支的数据集和特征集。</li>
<li>（3）重复（1）（2）步，直到子集包含单一特征，则为分支叶节点。</li>
</ul>
</li>
<li><p>信息熵：是度量样本集合纯度最常用的一种指标，假定当前样本集合 $D$ 中第  $k$ 类样本所占的比例为 $p_k(k = 1, 2, …, c)$ ，则 $D$ 的信息熵定义为： </p>
<script type="math/tex; mode=display">
Ent(D)= -\sum_{k=1}^{c}p_klog_2 p_k</script><p> $Ent(D)$ 的值越小，则 $D$ 的纯度越高。注意因为 $p_k \le 1$ ，因此 $Ent(D)$ 也是一个大于等于０小于１的值。$p_i = \frac{|C_k|}{|D|}$, 其中Ck表示集合 D 中属于第 k 类样本的样本子集。</p>
<p>信息熵：</p>
<script type="math/tex; mode=display">
H(D)= -\sum_{k=1}^{c}\frac{|C_k|}{|D|}log_2 \frac{|C_k|}{|D|}</script><p>针对某个特征A，对于数据集D的条件熵：也就是考虑到不同的分支结点所包含的样本数不同，给分支结点赋予权重 $\frac{|D^i|}{|D|}$ </p>
<script type="math/tex; mode=display">
H(D|A) =\sum_{i=1}^{n}\frac{|D_i|}{|D|}H(D_i) = -\sum_{i=1}^{n}\frac{|D_i|}{|D|}(\sum_{k=1}^{c}\frac{|C_{ik}|}{|D_i|}log_2 \frac{|C_{ik}|}{|D_i|})</script><p>信息增益== 信息熵-条件熵：</p>
<script type="math/tex; mode=display">
Gain(D,a) = H(D) - H(D|A)</script><p><strong>信息增益越大越好，因为其代表着选择该属性进行划分所带来的纯度提升</strong>，因此全部计算当前样本集合 $D$ 中存在不同取值的那些属性的信息增益后，取信息增益最大的那个所对应的属性作为划分属性即可。</p>
</li>
<li><p>优缺点</p>
<ul>
<li>ID3算法没有进行决策树剪枝，容易发生过拟合</li>
<li>ID3算法没有给出处理连续数据的方法，只能处理离散特征</li>
<li>ID3算法不能处理带有缺失值的数据集,需对数据集中的缺失值进行预处理</li>
<li><strong>信息增益准则对可取值数目较多的特征有所偏好</strong>  <strong>(信息增益反映的给定一个条件以后不确定性减少的程度,必然是分得越细的数据集确定性更高,也就是条件熵越小,信息增益越大)</strong></li>
</ul>
</li>
</ul>
<h5 id="C4-5算法（信息增益率）"><a href="#C4-5算法（信息增益率）" class="headerlink" title="C4.5算法（信息增益率）"></a>C4.5算法（信息增益率）</h5><p><strong>C4.5主要是克服ID3使用信息增益进行特征划分对取值数据较多特征有偏好的缺点</strong>。使用<strong>信息增益率</strong>进行特征划分。</p>
<ul>
<li><p>对ID3算法的改进：</p>
<ul>
<li><p>引入剪枝策略，使用悲观剪枝策略进行后剪枝。</p>
</li>
<li><p>使用信息增益率代替信息增益，作为特征划分标准</p>
</li>
<li><p>连续特征离散化</p>
</li>
<li><ul>
<li>需要处理的样本或样本子集按照连续变量的大小从小到大进行排序</li>
<li>假设该属性对应的不同的属性值一共有N个,那么总共有N−1个可能的候选分割阈值点,每个候选的分割阈值点的值为上述排序后的属性值中两两前后连续元素的中点,根据这个分割点把原来连续的属性分成两类</li>
</ul>
</li>
<li><p>缺失值处理</p>
</li>
<li><ul>
<li>对于具有缺失值的特征，用没有缺失的样本子集所占比重来折算信息增益率，选择划分特征</li>
<li>选定该划分特征，对于缺失该特征值的样本，将样本以不同的概率划分到不同子节点</li>
</ul>
</li>
</ul>
</li>
<li><p>信息增益率，信息增益率表示如下：</p>
<script type="math/tex; mode=display">
Gain\_ratio(D,a) = \frac{Gain(D,a)}{IV(a)}</script><script type="math/tex; mode=display">
IV(a) = \sum_{v=1}^{V}\frac{|D^v|}{|D|}log_2 \frac{|D^v|}{|D|}</script><p> $IV(a) $称为属性 a 的“固有值”。属性 a 的可能取值数目越多，则 $IV(a)$ 的值通常会越大，信<strong>息增益率对可取值较少的特征有所偏好（分母越小，整体越大）</strong>因此一定程度上抵消了信息增益对可取值数目多的属性的偏好。<strong>但是</strong>C4.5 并不是直接用增益率最大的特征进行划分，而是使用一个<strong>启发式方法</strong>：<strong>先从候选划分特征中找到信息增益高于平均值的特征，再从中选择增益率最高的</strong>。</p>
</li>
<li><p>决策树剪枝：</p>
<ul>
<li>决策树剪枝是为了防止过拟合</li>
<li>C4.5采用的是后剪枝策略进行剪枝：在决策树构造完成后，自底向上对非叶节点进行评估，如果将其换成叶节点能提升泛化性能，则将该子树换成叶节点。后剪枝决策树欠拟合风险很小，泛化性能往往优于预剪枝决策树。但训练时间会大很多。</li>
</ul>
</li>
<li><p>C4.5的优缺点</p>
<ul>
<li>C4.5只能用于分类</li>
<li>C4.5 在构造树的过程中，对数值属性值需要按照其大小进行排序，从中选择一个分割点，所以只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时，程序无法运行。</li>
<li>在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，算法低效。</li>
<li>对于连续值属性来说，可取值数目不再有限，因此可以采用离散化技术（如二分法）进行处理。将属性值从小到大排序，然后选择中间值作为分割点，数值比它小的点被划分到左子树，数值不小于它的点被分到右子树，计算分割的信息增益率，选择信息增益率最大的属性值进行分割。</li>
</ul>
</li>
</ul>
<h5 id="CART算法（基尼系数）"><a href="#CART算法（基尼系数）" class="headerlink" title="CART算法（基尼系数）"></a>CART算法（基尼系数）</h5><p>相比ID3和C4.5算法，CART算法使用二叉树简化决策树规模，提高生成决策树效率。</p>
<ul>
<li><p>CART树在C4.5基础上改进</p>
<ul>
<li>CART使用二叉树来代替C4.5的多叉树，提高了生成决策树效率</li>
<li>C4.5只能用于分类，<strong>CART树可用于分类和回归</strong></li>
<li>CART 使用基尼（Gini）系数作为变量的不纯度量，减少了大量的对数运算</li>
<li>CART 采用代理测试来估计缺失值，而 C4.5 以不同概率划分到不同节点中</li>
<li>CART 采用“基于代价复杂度剪枝”方法进行剪枝，而 C4.5 采用悲观剪枝方法</li>
<li>ID3 和 C4.5 层级之间只使用一次特征，CART 可多次重复使用特征</li>
</ul>
</li>
<li><p>CART是一棵二叉树，采用二元切分法，每次把数据分成两份，分别进入左子树、右子树。并且每个非叶子节点都有两个孩子，所以CART的叶子节点比非叶子节点多一。相比于ID3和C4.5，CART的应用要多一些，既可以用于分类也可以用于回归。CART分类时，选择基尼指数（Gini）为最好的分类特征，gini描述的是纯度，与信息熵含义类似，CART中每次迭代都会降低基尼系数。基尼值：</p>
<script type="math/tex; mode=display">
Gini(D) = \sum_{k=1}^{c} \sum_{k^, \not =k}p_kp_{k^,} = 1- \sum_{k=1}^{c}p_k^2 = 1-\sum_{k=1}^{c}(\frac{D^k}{D})^2</script><p>直观来看，$Gini(D)$ 反映了从数据集 $D$ 中随机抽取两个样本，其类别标记不一致的概率，因此$Gini(D)$ 越小，则数据集 $D$ 的纯度越高。</p>
<p>对于样本D，个数为|D|，根据特征A的某个值a，把D分成|D1|和|D2|，则在特征A的条件下，<strong>样本D的基尼系数表达式为：</strong></p>
<script type="math/tex; mode=display">
Gini\_index(D,A) = \frac{|D^1|}{|D|}Gini(D^1)+ \frac{|D^2|}{|D|}Gini(D^2)</script><p>于是，我们在候选属性集合A中，选择那个使得划分后基尼系数最小的属性作为最优划分属性即可。</p>
</li>
<li><p><strong>缺失值处理</strong></p>
<p>CART 算法使用一种惩罚机制来抑制提升值，从而反映缺失值的影响。为树的每个节点都找到代理分裂器，当 CART 树中遇到缺失值时，这个实例划分到左边还是右边是决定于其排名最高的代理，如果这个代理的值也缺失了，那么就使用排名第二的代理，以此类推，如果所有代理值都缺失，那么默认规则就是把样本划分到较大的那个子节点。</p>
</li>
<li><p>决策分类树</p>
<p><strong>CART作为分类树时，特征属性可以是连续类型也可以是离散类型，但观察属性(即标签属性或者分类属性)必须是离散类型</strong>。</p>
<p>先说分类树，ID3、C4.5在每一次分支时，是穷举每一个特征属性的每一个阈值，找到使得按照特征值&lt;=阈值，和特征值&gt;阈值分成的两个分支的熵最大的特征和阈值。按照该标准分支得到两个新节点，用同样的方法进行分支，直到所有人被分入性别唯一的叶子节点，或达到预设的终止条件，若最终叶子节点中性别不唯一，则以多数人的性别作为该叶子节点的性别。</p>
</li>
<li><p>决策回归树</p>
<p>回归树总体流程也是类似，不过在每个节点(不一定是叶子节点)都会得到预测值，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分支时穷举每个特征的每个阈值，找最好的分割点，但衡量的标准变成了最小化均方误差，即（每个人的年龄-预测年龄）^2 的总和 / N，或者说是每个人的预测误差平方和 除以 N。这很好理解，被预测出错的人数越多，错的越离谱，均方误差越大，通过最小化均方误差找最靠谱的分支依据。分支直到每个叶子节点上的人的年龄都唯一(这太难了)，或者达到预设的终止条件(如叶子个数上限)，若最终叶子节点上人的年龄不唯一，则以该节点上所有人的平均年龄作为该叶子节点的预测年龄。</p>
<p>对于决策树建立后做预测的方式，CART 分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。而回归树输出不是类别，它采用的是用最终叶子的均值或者中位数来预测输出结果。</p>
</li>
<li><p><strong>剪枝策略</strong>：采用一种“<strong>基于代价复杂度的剪枝</strong>”方法进行后剪枝</p>
</li>
</ul>
<h5 id="对比总结"><a href="#对比总结" class="headerlink" title="对比总结"></a>对比总结</h5><p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/3.png" alt=""></p>
<ul>
<li><strong>Bagging+决策树=随机森林</strong></li>
<li><strong>Boosting+决策树=GBDT</strong></li>
</ul>
<h4 id="随机森林（Bagging）"><a href="#随机森林（Bagging）" class="headerlink" title="随机森林（Bagging）"></a>随机森林（Bagging）</h4><p>随机森林本质上就是构建很多弱决策树，然后整合成森林，来确定最终的预估结果。<strong>Bagging+决策树=随机森林</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/4.jpg" style="zoom:80%;" /></p>
<p>随机森林的主要特点可以总结为如下2点：<strong>数据随机性选取，待选特征的随机选取</strong>。主要是为了消除过拟合问题。随机森林使用CART树作为弱学习器，生成树的过程中不进行剪枝<strong>，确定最终结果时，分类使用投票机制，回归问题使用平方误差最小化。</strong></p>
<p>随机森林根据下面步骤来构建：</p>
<ol>
<li>M来表示训练样本的个数，N表示特征数目</li>
<li>输入特征数目n，用于确定决策树一个节点的决策结果；其中n应远小于N</li>
<li>M个训练样本中，有放回抽样的方式，取样k次，形成训练集，并用未抽到样本做预测，评估误差</li>
<li>随机选择n个特征，每棵决策树上每个节点的决策基于这些特征确定。根据这n个特征，计算其最佳的分裂方式</li>
<li>最后根据每棵树，以多胜少方式决定分类</li>
</ol>
<p>优点：</p>
<ul>
<li>很容易查看模型的输入特征的相对重要性</li>
<li>可以处理高维数据</li>
<li>超参数的数量不多，而且它们所代表的含义直观易懂</li>
<li>随机森林有足够多的树，分类器就不会产生过度拟合模型</li>
</ul>
<p>缺点：</p>
<ul>
<li>使用大量的树会使算法变得很慢，无法做到实时预测</li>
<li>对于回归问题，精准度不够</li>
<li>抗噪声干扰能力弱，无法自动处理异常样本</li>
<li>模型越深越容易过拟合</li>
</ul>
<h4 id="Boosting算法代表"><a href="#Boosting算法代表" class="headerlink" title="Boosting算法代表"></a>Boosting算法代表</h4><h5 id="AdaBoost算法"><a href="#AdaBoost算法" class="headerlink" title="AdaBoost算法"></a>AdaBoost算法</h5><ul>
<li>特点<ul>
<li>不改变所给的训练数据，而不断改变训练数据权值的分布，使得训练数据在基本分类器的学习中起到不同的作用</li>
<li>利用基本分类器的线性组合构建最终的分类器</li>
</ul>
</li>
</ul>
<p>假定给定一个二分类分类的训练数据：</p>
<script type="math/tex; mode=display">
T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}</script><p>其中每个样本点由实例与标记组成。实例 $x_i \in \chi \subseteq R^n$ ，标记 $y_i \in \Upsilon = \{-1,1\}$ ，$\chi$ 是实例空间，$\Upsilon$ 是标记集合。Adaboost 利用以下算法，从训练数据中学习一系列弱分类器，并将这些弱分类器线性组合成为一个强分类器。</p>
<p>（1）初始化训练数据的权值分布：</p>
<script type="math/tex; mode=display">
D_1 = (w_{11},...,w_{1i},...,w_{1N}),\quad w_{1i}=\frac{1}{N},\quad i=1,2,...,N</script><blockquote>
<p>假设训练数据集具有均匀的权值分布，即每个训练样本在基本分类器的学习中作用相同。这一假设保证第１步能够在原始数据上学习基本分类器 $G_1(x)$ 。</p>
</blockquote>
<p>（2）一共需要学习 M 个基本分类器，则在每一轮 $m = 1,2,…,M$ 顺次地执行下列操作：</p>
<ul>
<li>a.<strong>使用当前分布 $D_m$ 加权的训练数据集，得到基本分类器：</strong></li>
</ul>
<script type="math/tex; mode=display">
G_m(x):\chi\rightarrow \{-1,+1\}</script><ul>
<li>b.<strong>计算 $G_m(x)$ 在训练数据集上的分类误差率：</strong></li>
</ul>
<script type="math/tex; mode=display">
e_m = \sum_{i=1}^{N}P(G_m(x_i)\not = y_i) = \sum_{G_{mi}\not = y_i}w_{mi}</script><p>$w_{mi}$ 表示第 m 轮中第 i 个实例的权值，$\sum_{i=1}^{N}w_{mi} = 1$ 。这表明，  $G_{m}(x)$  在加权的训练数据集上的分类误差率是被 $G_{m}(x)$  误分类的样本的权值之和。</p>
<ul>
<li><p>c.<strong>计算 $G_{m}(x)$ 的系数：</strong></p>
<script type="math/tex; mode=display">
\alpha_m = \frac{1}{2}ln \frac{1-e_m}{e_m}</script><p>$\alpha_m$ 表示 $G_{m}(x)$ 在最终分类器中的重要性。根据式子可知，$e_m \le \frac{1}{2}$ 时，$\alpha_m \ge 0$ ，并且 $\alpha_m$ 随着 $e_m$ 的减小而增大，所以分类误差率越小的基本分类器在最终分类器中的作用越大。<strong>这里注意所有 $\alpha_m$ 加起来的和并不等于 1 。</strong> （<u>注意 $e_m$ 是有可能比 $\frac{1}{2}$ 大的，也就是说 $\alpha_m$ 有可能小于 0，《统计学习方法》没有讨论这种情况的处理方法，但在西瓜书中的处理方法是抛弃该分类器，且终止学习过程，哪怕学习到的分类器个数远远没有达到预设的 M</u>）</p>
</li>
<li><p>e.<strong>更新训练数据集的权值分布：</strong></p>
</li>
</ul>
<script type="math/tex; mode=display">
D_{m+1} = (w_{m+1,1},...,w_{m+1,i},...,w_{m+1,N})</script><script type="math/tex; mode=display">
w_{m+1,i} = \frac{w_{mi}}{Z_m}exp(-\alpha_my_iG_m(x_i)), \quad i=1,2,...,N</script><script type="math/tex; mode=display">
其中 Z_m是规范因子，Z_m = \sum_{i=1}^{N}w_{mi}exp(-\alpha_my_iG_m(x_i))</script><p>​    $w_{m+1,i}$ 也可以写成分段函数的形式：</p>
<script type="math/tex; mode=display">
w_{m+1,i}= \begin {cases} 
\frac{w_{mi}}{Z_m}e^{-\alpha_m}, & G_m(x_i) = y_i \\
\frac{w_{mi}}{Z_m}e^{\alpha_m}, & G_m(x_i) \not = y_i
\end {cases}</script><p>​        也就是说被基本分类器 $G_m(x)$ 误分类样本的权值得以增大，而被正确分类的样本的权值却变小。两者相比可知误分类样本的权值被        放    大 $e^{2\alpha_m} = \frac{1-e_m}{e_m}$ 倍。因此，误分类样本在下一轮学习中起更大的作用。</p>
<p>（3）经过以上过程后可以得到 M 个基本分类器，构建基本分类器的线性组合：</p>
<script type="math/tex; mode=display">
f(x) = \sum_{m=1}^{M}\alpha_m G_m(x)</script><p>​    通过线性组合得到最终的分类器：</p>
<script type="math/tex; mode=display">
G(x) = sign(f(x)) = sign(\sum_{m=1}^{M}\alpha_m G_m(x))</script><p>​    线性组合 $f(x)$ 实现 M 个基本分类器的加权表决，$f(x)$ 的符号决定了实例 $x$ 的类，$f(x)$ 的绝对值表示分类的确信度。</p>
<h5 id="GBDT算法"><a href="#GBDT算法" class="headerlink" title="GBDT算法"></a>GBDT算法</h5><p>GBDT（Gradient Boosting Decision Tree）梯度迭代树，是Boosting算法的一种。</p>
<p><strong>GBDT使用的弱学习器必须是CART，且必须是回归树。</strong>GBDT用来做回归预测，当然，通过设置阈值也能用于分类任务。在模型训练时，模型预测样本损失尽可能小。</p>
<p><strong>GBDT直观理解：模型的每一轮预测和真实值有gap，这个gap称为残差。下一轮对残差进行预测，最后将所有预测结果相加，就可以得到最终结果。</strong>也就是说，模型的结果是一组回归分类树组合：T1，T2，…，Tk，其中Tj学习的是之前j-1课树预测结果的残差。这种思想就像准备考试前的复习，先做一遍习题册，然后把做错的题目挑出来，再做一次，然后把做错的题目挑出来在做一次，经过反复多轮训练，取得最好的成绩。</p>
<p>GBDT学习的是残差，而本质是在<strong>学习负梯度信息</strong>，由于一般回归使用<strong>平方损失（L2 loss）</strong>，他的导数就是残差，所以GBDT学的是残差。</p>
<p>GBDT和AdaBoost的模型的表示形式都可以：</p>
<script type="math/tex; mode=display">
f(x) = \sum_{m=1}^M \alpha_m G_m(x)</script><p><strong>只是 AdaBoost</strong> 在训练完一个 $G_m(x)$ 后会重新赋值样本的权重：分类错误的样本的权重会增大而分类正确的样本的权重则会减小。这样在训练时 $G_{m+1}(x)$ 会侧重对错误样本的训练，以达到模型性能的提升，</p>
<p><strong>但是AdaBoost</strong>模型每个基分类器的损失函数优化目标是相同的且独立的，都是最优化当前样本（样本权重）的指数损失。</p>
<p>GBDT是一个加性模型，但其是通过不断迭代拟合样本真实值与当前分类器预测的残差来逼近真实值的。可以形象地理解如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/5.png" style="zoom:50%;" /></p>
<p>按照这个思路，第 m 个基分类器的预测结果为：</p>
<script type="math/tex; mode=display">
f_m(x) = f_{m-1}(x)+\alpha_mG_m(x)</script><p>而 $G_m(x)$ 的优化目标就是最小化当前预测结果 $f_{m-1}(x_i)+\alpha G(x_i)$ 与真实值 $y_i$ 之间的差距。</p>
<script type="math/tex; mode=display">
(\alpha_m,G_m(x)) = arg min_{\alpha,G}\sum_{i=1}^{N}L(y_i,\quad f_{m-1}(x_i)+\alpha G(x_i))</script><p>GBDT树的学习过程为：计算伪残差-&gt; 生成基学习器 -&gt; 目标函数优化 -&gt; 更新模型</p>
<p>其思想类似于数值优化中梯度下降求参方法，参数沿着梯度的负方向以小步长前进，最终逐步逼近参数的局部最优解。在GB中模型每次拟合残差，逐步逼近最终结果。</p>
<p>如上所述，我们每个 stage 的优化目标是：<strong>（一阶泰勒）</strong></p>
<script type="math/tex; mode=display">
G_m(x) = arg min_{G}\sum_{i=1}^{N}L(y_i,\quad f_{m-1}(x_i)+\alpha_m G_{m}(x_i))</script><script type="math/tex; mode=display">
这一块太乱，回来再重新总结一遍。经过一阶泰勒展开得到：</script><script type="math/tex; mode=display">
arg min_{G}\sum_{i=1}^{N}L(y_i,\alpha_m G_{m-1}(x_i))+f_{m-1}(x_i)+\frac{\partial L(y_i,f_m(x_i))}{\partial f_m(x_i)}\\</script><p>该函数比较难求解，类似于梯度下降方法，给定 $f_{m-1}(x_i)$ 的一个近似解，$\alpha_mG_m(x)$ 可以看作是 $f_{m-1}(x_i)$ 逼近 $f_m(x_i)$ 的步长和方向。所以：</p>
<script type="math/tex; mode=display">
f_m(x)= f_{m-1}(x)-\alpha_m [\frac{\partial L(y_i,f_m(x_i))}{\partial f_m(x_i)}]_{f_m(x_i)=f_{m-1}(x_i)}</script><script type="math/tex; mode=display">
\alpha_m = arg min_{\alpha}\sum_{i=1}^{N}L(y_i,f_{m-1}(x)-\alpha_m [\frac{\partial L(y_i,f_m(x_i))}{\partial f_m(x_i)}]_{f_m(x_i)=f_{m-1}(x_i)} )</script><p>上面的损失函数 L 可以根据问题的不同使用不同的损失函数，而且还可以<strong>加上模型复杂度的正则项等等来尽量避免过拟合</strong>。</p>
<p><strong>GBDT缺点</strong>：基于残差的gbdt在解决回归问题上不算好的选择，对异常值过于敏感；不适合高纬稀疏特征；不好并行计算。</p>
<h5 id="XGBoost算法"><a href="#XGBoost算法" class="headerlink" title="XGBoost算法"></a>XGBoost算法</h5><p>XGBoost和GBDT都是属于Grandient Boosting，本质思想与GBDT一致，构建多个基学习器使用加法模型，学习前面基学习器的结果与真实值的偏差，通过多个学习器的学习，不断降低模型值和实际值的差。XGBoost 可以认为是 GBDT 的一个实现，但是XGBoost相比GBDT做了如下的改进：</p>
<ul>
<li>GBDT将目标函数泰勒展开到一阶，而xgboost将目标函数泰勒展开到二阶，XGBoost保留更多有关目标函数的信息。</li>
<li>GBDT是给新的基模型寻找新的拟合标签（前面加法模型的负梯度），而XGBoost是给新的基模型寻找新的目标函数（目标函数关于新的基模型的二阶泰勒展开）。</li>
<li><strong>XGBoost加入了和叶子权重的L2正则化</strong>，有利于模型获得更低的方差。</li>
<li><strong>XGBoost增加了自动处理缺失值特征的策略</strong>，通过把带缺失值的样本划分到左子树或右子树，比较两种方案下目标函数的优劣，从而自动对有缺失值的样本进行划分，无需对缺失值特征进行填充预处理。如果训练中没有数据缺失，预测时出现了数据缺失，那么默认被分类到右子树。</li>
<li>支持并发，xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。<strong>xgboost的并行是在特征粒度上的</strong>。节点分裂时，计算特征增益是多线程并行的。</li>
<li><strong>基分类器：</strong>传统的GBDT采用CART作为基分类器，XGBoost支持多种类型的基分类器，比如线性分类器。</li>
<li><strong>子采样：</strong>传统的GBDT在每轮迭代时使用全部的数据，XGBoost则采用了与随机森林相似的策略，支持对数据进行采样。</li>
</ul>
<p>最终分类器可以用这个公式表示：</p>
<script type="math/tex; mode=display">
f(x) = \sum_{m=1}^M G_m(x)</script><p>优化的目标：</p>
<script type="math/tex; mode=display">
Obj = \sum_{i=1}^N L(y_i,f(x_i))+\sum_{m = 1}^{M}\Omega(G_m(x))</script><p>其中 $N$ 为样本数量，$y_i$ 表示样本真实值，$f(x)$ 是模型输出，所以前半部分代表模型的损失函数。$M$ 表示树的个数，$G_m(x)$ 表示第 $m$ 棵树，<strong>$\Omega$ 是模型复杂度函数，是一个正则项</strong>。模型越复杂，越容易出现过拟合，所以采用这样的目标函数，为了使得最终的模型既有很好的准确度也有不错的泛化能力。</p>
<p><strong>追加法训练：</strong></p>
<p>核心的思想是，已经训练好的树 $T1…T_{t-1}$ 不再调整。根据目标函数最小原则，新增树 $T_t$ ，表示如下：</p>
<script type="math/tex; mode=display">
f_0(x) = 0 \quad 算法初始化</script><script type="math/tex; mode=display">
f_1(x) = G_1(x) = f_0(x)+G_1(x)\quad 训练第１棵树 G_1(x)</script><script type="math/tex; mode=display">
f_2(x) = G_1(x)+G_2(x) = f_1(x)+G_2(x) \quad 训练第２棵树 G_2(x)</script><script type="math/tex; mode=display">
f_t(x) = \sum_{m = 1}^{t} f_m(x) = f_{t-1}(x)+G_t(x) \quad 训练第t棵树，前面t-1棵不再调整</script><p>假设此时对第 t 棵树训练，则目标函数表示为：</p>
<script type="math/tex; mode=display">
Obj^{(t)} = \sum_{i=1}^N L(y_i,f_t(x_i))+\sum_{m = 1}^{t}\Omega(G_m(x)) \\
=\sum_{i=1}^{N}L(y_i, f_{t-1}(x_i)+ G_t(x_i)+\Omega(G_t(x))+constant</script><p>其中 constant 常数代表 $\sum_{m=1}^{t-1}\Omega(G_m(x))$ ，因为前面 t-1 棵树结构不再变化，所以他们的复杂度为常数。</p>
<p>回顾高等数学中的泰勒展开，它使用一个函数的高阶导数，用多项式的形式逼近原始函数。当展开到二阶导数的时候公式如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/6.jpg" alt=""></p>
<p>利用泰勒展开公式和上面推导的 $Obj^{(t)}$ ， $Obj^{(t)}$ 式中，$f_{t-1}(x)$ 对应泰勒公式中的 $x$，而 $G_t(x)$ 是一棵待增加的新树，对应泰勒公式中的 $\Delta x$ ，$L(y_i,f_{t-1}(x))$ 对应泰勒公式中的 $f(x)$ ，而 $L(y_i, f_{t-1}(x_i)+ G_t(x_i)$ 对应泰勒公式中的 $f(x+\Delta x)$ ，则对 $L(y_i, f_{t-1}(x_i)+ G_t(x_i)$ 做二阶泰勒展开，得：</p>
<script type="math/tex; mode=display">
Obj^{(t)} =\sum_{i=1}^{N}[L(y_i, f_{t-1}(x_i))+ g_iG_t(x_i)+\frac{1}{2}h_iG_t^2(x_i)]+\Omega(G_t(x))+constant</script><p>其中：</p>
<script type="math/tex; mode=display">
g_i = \frac{\partial L(y_i, f_{t-1}(x_i))}{\partial f_{t-1}(x_i)} \quad 一阶导数 \\
h_i = \frac{\partial L(y_i, f_{t-1}(x_i))}{\partial^2 f_{t-1}(x_i)} \quad 二阶导数</script><p>因为我们求解的目标是使得 $Obj^{(t)}$ 最小的 $G_t(x)$ 。当前面 $t-1$ 棵树都已经确定时， $\sum_{i=1}^{N}[L(y_i, f_{t-1}(x_i))$ 是一个常量，可以省略，constant 常量也可以省略，因此简化得到新的目标函数：</p>
<script type="math/tex; mode=display">
Obj^{(t)} =\sum_{i=1}^{N}[ g_iG_t(x_i)+\frac{1}{2}h_iG_t^2(x_i)]+\Omega(G_t(x))</script><p>从XGBoost原理部分可以看出，XGBoost的实现中，采用了<strong>二阶泰勒</strong>展开公式展开来近似损失函数，同时在求解树的过程中，<strong>使用了贪心算法</strong>，并使用枚举特征，样本按照特征排序后，采用线性扫描找到最优分裂点。这种实现方法，是对GDBT思想的逼近，但是在工程上确非常有效。</p>
<h5 id="对比总结-1"><a href="#对比总结-1" class="headerlink" title="对比总结"></a>对比总结</h5><h4 id="K-means聚类算法"><a href="#K-means聚类算法" class="headerlink" title="K-means聚类算法"></a>K-means聚类算法</h4><h5 id="K-means算法"><a href="#K-means算法" class="headerlink" title="K-means算法"></a>K-means算法</h5><ul>
<li><p>算法简介：</p>
<ul>
<li><p>k-means是一种聚类算法，聚类就是指在不知道任何样本的标签情况下，通过数据之间的内在关系将样本分成若干个类别，使得相同类别样本之间的相似度搞，不同类别之间的样本相似度低。因此，<strong>k-mean算法是属于非监督学习的范畴</strong>。</p>
</li>
<li><p>k是指k个簇（cluster），means是指每个簇内的样本均值，也就是聚类中心</p>
</li>
<li><p>基本思想：通过迭代的方式寻找 k 个簇的划分方案，使得聚类结果对应的代价函数最小。<strong>代价函数可以定义为各个样本距离它所属的簇的中心点的误差平方和</strong>：</p>
<script type="math/tex; mode=display">
J(c,\mu)=\sum_{i=1}^{N} ||x_{i} - \mu _{c_{i}}||^{2} \\
其中，x_{i}代表第i个样本，c_{i}是x_{i}所属的簇，\mu_{c_{i}}代表簇对应的中心点（即均值），N是样本总数.</script></li>
</ul>
</li>
<li><p>算法流程：</p>
<p>k-means算法采用了<strong>贪心策略</strong>，通过多次迭代来近似求解上面的代价函数，具体算法流程如下：</p>
<ul>
<li><p>（1）随机选取 k 个点作为初始聚类（簇）中心，记为 $\mu_{1}^{(0)},\mu_{2}^{(0)},…,\mu_{k}^{(0)}$。</p>
</li>
<li><p>（2）计算每个样本 $x_{i}$ 到各个簇中心的距离（<strong>欧式距离</strong>，余弦相似度），将其分配到与它距离最近的簇。</p>
<script type="math/tex; mode=display">
c_{i}^{(t)} \leftarrow \underset{k'}{argmin} ||x_{i}-\mu _{k'}^{(t)}||^{2} \\ 
其中,t为当前迭代步数，k'为第k'个簇（类别）(k'=1,2,..,k)</script></li>
<li><p>（3）对于每个簇，利用该簇中的样本重新计算该簇的中心（即均值向量）：</p>
<script type="math/tex; mode=display">
\mu_{k}^{(t+1)} \leftarrow \underset{\mu}{argmin} \sum_{i:c_{i}^{(t)}=k'} ||x_{i}-\mu||^{2}</script></li>
<li><p>（4）重复迭代上面2-3步骤 T 次，若聚类结果保持不变，则结束。</p>
</li>
</ul>
</li>
<li><p>k-means算法的优点</p>
<ul>
<li>算法简单易实现。</li>
<li>对于大数据集，这种算法相对可伸缩且是高效的，计算复杂度为 $O(TNk)$ 接近于线性（其中T是迭代次数、N是样本总数、k为聚类簇数）。</li>
<li>虽然以局部最优结束，但一般情况下达到的局部最优已经可以满足聚类的需求。</li>
</ul>
</li>
<li><p>k-means算法的缺点</p>
<ul>
<li>需要人工预先确定初始K值，该值与实际的类别数可能不吻合。</li>
<li><strong>K均值只能收敛到局部最优。</strong>因为求解这个代价函数是个NP问题，采用的是贪心策略，所以只能通过多次迭代收敛到局部最优，而不是全局最优。</li>
<li><strong>K均值的效果受初始值和离群点的影响大。</strong>因为 k 均值本质上是基于距离度量来划分的，均值和方差大的维度将对数据的聚类结果产生决定性的影响，因此需要进行<strong>归一化处理</strong>；此外，离群点或噪声对均值会产生影响，导致中心偏移，因此需要进行预处理。</li>
<li>对于数据簇分布差别较大的情况聚类效果很差。例如一个类别的样本数是另一类的100倍。</li>
<li>样本只能被划分到一个单一的类别中。</li>
<li>不适合太离散的分类、样本类别不平衡的分类、非凸形状的分类。</li>
<li>对异常值敏感。</li>
</ul>
</li>
</ul>
<h5 id="K-means-算法"><a href="#K-means-算法" class="headerlink" title="K-means++算法"></a>K-means++算法</h5><p>由于 k-means 算法中，初始K值是人为地凭借经验来设置的，聚类的结果可能不符合实际的情况。因此，K值的设置对算法的效果影响其实是很大的，那么，如何设置这个K值才能取得更好的效果呢？</p>
<p><strong>k-means++的主要思想：</strong></p>
<ul>
<li>首先随机选取1个初始聚类中心（n=1）。</li>
<li>假设已经选取了n个初始聚类中心（0&lt;n&lt;k），那么在选择第n+1个聚类中心时，距离当前已有的n个聚类中心越远的点越有可能被选取为第n+1个聚类中心。</li>
<li>按照 k-means 算法去优化。</li>
<li>可以这样理解上面的思想：<strong>聚类中心自然是越互相远离越好，即不同的类别尽可能地分开</strong>。</li>
<li>缺点：难以并行化。</li>
</ul>
<blockquote>
<p>k-means++算法虽然可以更好地初始k个聚类中心，但还是不能解决一个问题，k 值应该取多少才算合理？</p>
</blockquote>
<h5 id="如何选取K值？"><a href="#如何选取K值？" class="headerlink" title="如何选取K值？"></a>如何选取K值？</h5><p>如何才能合理地选取k值是k-means算法最大的问题之一，一般可以采取手肘法和<code>Gap Statistic</code>方法。</p>
<h6 id="手肘法"><a href="#手肘法" class="headerlink" title="手肘法"></a>手肘法</h6><p>k值的选择一般基于经验或者多次实验来确定，手肘法便是如此，其主要思想是：通过多次实验分别选取不同的k值，将不同k值的聚类结果对应的最小代价画成折线图，将曲线趋于平稳前的拐点作为最佳k值。如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/8.png" style="zoom:50%;" /></p>
<blockquote>
<p>上图中，k取值在1~3时，曲线急速下降；当k&gt;3时，曲线趋于平稳。因此，在k=3处被视为拐点，所以手肘法认为最佳的k值就是3。</p>
</blockquote>
<h6 id="Gap-Statistic"><a href="#Gap-Statistic" class="headerlink" title="Gap Statistic"></a>Gap Statistic</h6><p>Gap Statistics 定义为：</p>
<script type="math/tex; mode=display">
Gap(k)=E(logD_{k})-logD_{k} \\
其中，D_{k}是第k簇聚类对应的损失值，E(logD_{k})是logD_{k}的期望。</script><p>对于上式的 $E(logD_{k})$，一般通过蒙特卡洛模拟产生。具体操作是：在样本所在的区域内，按照均匀分布随机产生和原样本数目一样的随机样本，计算这些随机样本的均值，得到一个 $D_{k}$，重复多次即可计算出 $E(logD_{k})$ 的近似值。</p>
<p>$Gap(k)$ 可以看做是随机样本的损失与实际样本的损失之差，假设实际样本最佳的簇类数目为 k，那么实际样本的损失应该相对较小，随机样本的损失与实际样本的损失的差值相应地达到最大，即<strong>最大的 $Gap(k)$ 值应该对应最佳的k值。</strong></p>
<p>因此，我们只需要用不同的k值进行多次实验，找出使得$Gap(k)$最大的k即可。</p>
<blockquote>
<p>到现在为止我们可以发现，上面的算法中，k值都是通过人为地凭借经验或者多次实验事先确定下来了的，但是当我们遇到高维度、海量的数据集时，可能就很难估计出准确的k值。那么，有没有办法可以帮助我们自动地确定k值呢？有的，下面来看看另一个算法。</p>
</blockquote>
<h5 id="ISODATA-算法"><a href="#ISODATA-算法" class="headerlink" title="ISODATA 算法"></a>ISODATA 算法</h5><p><strong>ISODATA 的全称是迭代自组织数据分析法。它解决了 K 的值需要预先人为的确定这一缺点。而当遇到高维度、海量的数据集时，人们往往很难准确地估计出 K 的大小。I</strong>SODATA 就是针对这个问题进行了改进。</p>
<p><strong>主要思想：</strong></p>
<ul>
<li>当某个类别样本数目过多、分散程度较大时，将该类别分为两个子类别。（分裂操作，即增加聚类中心数）</li>
<li>当属于某个类别的样本数目过少时，把该类别去除掉。（合并操作，即减少聚类中心数）</li>
</ul>
<p><strong>算法优点：</strong>可以自动寻找合适的k值。</p>
<p><strong>算法缺点：</strong> 除了要设置一个参考聚类数量 $k_{0}$ 外，还需要指定额外的3个阈值，来约束上述的分裂和合并操作。具体如下：</p>
<ol>
<li>预期的聚类数目  $k_{0}$ 作为参考值，最终的结果在  $k_{0}$ 的一半到两倍之间。</li>
<li>每个类的最少样本数目 $N_{min}$，若分裂后样本数目会少于该值，则该簇不会分裂。</li>
<li>最大方差  $Sigma$，用于控制某个簇的样本分散程度，操作该值且满足条件2，则分裂成两个簇。</li>
<li>两个簇最小距离  $D_{min}$，若两个簇距离小于该值，则合并成一个簇。</li>
</ol>
<h5 id="K-means和-KNN-算法的区别"><a href="#K-means和-KNN-算法的区别" class="headerlink" title="K-means和 KNN 算法的区别"></a>K-means和 KNN 算法的区别</h5><p><strong>KNN：</strong>KNN的全称是K Nearest Neighbors，意思是K个最近的邻居。K个最近邻居，K的取值肯定是至关重要的。那么最近的邻居又是怎么回事呢？其实啊，KNN的原理就是当预测一个新的值x的时候，根据它距离最近的K个点是什么类别来判断x属于哪个类别。<strong>注意KNN算法是有监督学习中的分类算法。</strong></p>
<ul>
<li><p><strong>1、距离的计算</strong>：欧式距离；曼哈顿距离；闵可夫斯基距离。</p>
</li>
<li><p><strong>2、K值的选取</strong>：<strong>通过交叉验证</strong>（将样本数据按照一定比例，拆分出训练用的数据和验证用的数据，比如6：4拆分出部分训练数据和验证数据），从选取一个较小的K值开始，不断增加K的值，然后计算验证集合的方差，最终找到一个比较合适的K值。</p>
<p>当你增大k的时候，一般错误率会先降低，因为有周围更多的样本可以借鉴了，分类效果会变好。但注意，当K值继续增大的时候，错误率会更高。这也很好理解，比如说你一共就35个样本，当你K增大到30的时候，KNN基本上就没意义了。</p>
<p>选择较小的k值，就相当于用较小的邻域中的训练实例进行预测，训练误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是泛化误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合。<br>　　<br>选择较大的k值，就相当于用较大邻域中的训练实例进行预测，其优点是可以减少泛化误差，但缺点是训练误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。</p>
<p><strong>选择K点的时候可以选择一个较大的临界K点，当它继续增大或减小的时候，错误率都会上升。</strong></p>
</li>
<li><p><strong>3、算法流程</strong>：</p>
<p>（1）计算测试数据与各个训练数据之间的距离；</p>
<p>（2）按照距离的递增关系进行排序；</p>
<p>（3）选取距离最小的K个点；</p>
<p>（4）确定前K个点所在类别的出现频率；</p>
<p>（5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。</p>
</li>
<li><p><strong>KNN的特点：非参，惰性</strong></p>
<ul>
<li>非参：<strong>非参</strong>的意思并不是说这个算法不需要参数，而是意味着这个模型不会对数据做出任何的假设，与之相对的是线性回归（我们总会假设线性回归是一条直线）。也就是说KNN建立的模型结构是根据数据来决定的。</li>
<li>惰性：KNN算法不需要大量的训练过程得到一个算法模型，他没有明确的训练数据的过程，或者说这个过程很快。</li>
</ul>
</li>
<li><p>优点：简单易用；模型训练时间快；预测效果好；对异常值不敏感</p>
</li>
<li><p>缺点：对内存要求较高，因为该算法存储了所有训练数据；预测阶段可能很慢；对不相关的功能和数据规模敏感</p>
</li>
</ul>
<p><strong>k-means和KNN的不同点：</strong></p>
<ul>
<li><code>KNN</code>为分类，<code>K-means</code>为聚类；</li>
<li><code>KNN</code>为监督学习，<code>K-means</code>为无监督学习；</li>
<li><code>KNN</code>的输入样本为带<code>label</code>的，<code>K-means</code>的输入样本不带<code>label</code>；</li>
<li><code>KNN</code>没有训练过程，<code>K-means</code>有训练过程；</li>
<li><code>K</code>的含义不同：<ul>
<li>KNN：直接把待分类点周边最近的k个点计数，数量多的那类定为待分类点的类别。无训练的过程。</li>
<li>K-means：先定好k个类别，然后随机确定k个坐标（聚类中心），各点离哪个坐标近就算做哪类，然后不停算平均值求出中心，直到稳定，聚类完成。有训练的过程。</li>
</ul>
</li>
</ul>
<p><strong>相同点：</strong>都是计算最近邻，一般都用欧氏距离。</p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/7.png" alt=""></p>
<h5 id="K-means和GMM算法的区别"><a href="#K-means和GMM算法的区别" class="headerlink" title="K-means和GMM算法的区别"></a>K-means和GMM算法的区别</h5><p>高斯混合模型（GMM），GMM是指具有如下形式的概率分布模型</p>
<script type="math/tex; mode=display">
P(x|\theta)=\sum_{k=1}^{K} \alpha_{k} \phi (x|\theta_{k})\\</script><script type="math/tex; mode=display">
其中，\alpha_{k}是高斯混合系数，\alpha_{k} \geq 0 \ 且\sum_{k=1}^{K}\alpha_{k}=1;</script><script type="math/tex; mode=display">
\theta_{k}=(\mu_{k},\sigma_{k}^{2});</script><script type="math/tex; mode=display">
\phi (x|\theta_{k})是第k个高斯分布模型的概率密度函数，具体形式如下：</script><script type="math/tex; mode=display">
\phi (x|\theta_{k})=\frac{1}{\sqrt {2\pi} \sigma_{k}} exp\left ( -\frac{(y-\mu_{k})^{2}}{2\sigma_{k}^{2}} \right )</script><script type="math/tex; mode=display">
其中，u_k是均值，\sigma_{k}^2是方差</script><p>$\phi (x|\theta_{k})$的值代表：x由参数$\theta_{k}$下的高斯模型生成的概率。据此可以<strong>==判断x属于第k个高斯模型生成的概率。==</strong></p>
<p><strong>GMM聚类：</strong>高斯混合模型（GMM）聚类的思想和 k-means 其实有点相似，都是通过迭代的方式将样本分配到某个簇类中，然后更新簇类的信息，不同的是GMM是基于概率模型来实现的，而 k-means 是非概率模型，采用欧氏距离的度量方式来分配样本。</p>
<p><strong>GMM聚类主要思想和流程：</strong></p>
<p>​    每个GMM由K个混合成分组成，每个混合成分都是一个高斯分布，$\alpha_{k}$ 为相应的混合系数。GMM模型假设所有的样本都根据高斯混合分    布生成，那么<strong>每个高斯分布其实就代表了一个簇类</strong>。具体流程如下：</p>
<p>​    （1）先初始化高斯混合模型的参数 $\{(\alpha_{k},\mu_{k},\sigma_{k}^{2})\ | \ 1\leq k \leq K \ \}$ ，训练一个GMM模型需要估计这些参数，如何估计后面会介绍。</p>
<p>​    （2）对每个样本，固定各个高斯分布，计算样本在各个高斯分布上的概率（即该样本是由某个高斯分布生成而来的概率）。</p>
<p>​    （3）然后固定样本的生成概率，更新参数以获得更好的高斯混合分布。</p>
<p>​    （4）迭代至指定条件结束。</p>
<p><strong>EM算法估计GMM参数</strong></p>
<p>上面提到，要训练一个GMM模型，就需要估计每个高斯分布的参数 $\{(\alpha_{k},\mu_{k},\sigma_{k}^{2})\ | \ 1\leq k \leq K \ \}$，才能知道每个样本是由哪个高斯混合成分生成的，也就是说，数据集的所有样本是可观测数据， $\{(\alpha_{k},\mu_{k},\sigma_{k}^{2})\ | \ 1\leq k \leq K \ \}$ 这些是待观测数据(隐变量)，而估计待观测数据常用的算法就是EM算法。</p>
<p><strong>EM（Expectation-Maximization）算法</strong>是常用的估计参数隐变量的礼器，它是一种迭代的方法，其主要的思想就是：若<strong>参数</strong>$\theta$ 已知，则可以根据训练数据推断出最优隐变量<strong>Z</strong>的值（E步），若Z的值已知，则可方便的对<strong>参数$\theta$</strong> 做最大似然估计（M步）。</p>
<p>EM算法估计高斯混合模型的参数的步骤：</p>
<ul>
<li><p>（1）给定数据集$D=\{x_{1},x_{2},…,x_{m} \}$，初始化高斯混合分布的模型参数 $\{(\alpha_{k},\mu_{k},\sigma_{k}^{2})\ | \ 1\leq k \leq K \ \}$。</p>
</li>
<li><p><strong>（2）E步：</strong>遍历每个样本，对每个样本 $x_{i}$，计算其属于第k个高斯分布的概率：</p>
<script type="math/tex; mode=display">
\gamma_{ik}=\frac{\alpha_{k}\phi(x_{i}|\theta_{k})}{\sum_{k=1}^{K}\alpha_{k}\phi(x_{i}|\theta_{k})} \ ,\quad 其中，\theta_{k}=(\mu_{k},\sigma_{k}^{2})</script></li>
<li><p><strong>（3）M步：</strong>更新各个高斯分布的参数为$\{(\hat{\alpha}_{k},\hat{\mu}_{k},\hat{\sigma}_{k}^{2})\ | \ 1\leq k \leq K \ \}$ :</p>
</li>
</ul>
<script type="math/tex; mode=display">
\hat{\alpha}_{k}=\frac{\sum_{i=1}^{m} \gamma_{ik}}{m} --- m个样本在该类的平均概率</script><script type="math/tex; mode=display">
\hat{\mu}_{k}=\frac{\sum_{i=1}^{m} \gamma_{ik} x_{i}}{\sum_{i=1}^{m} \gamma_{ik}}  --- m个样本特征值的加权平均</script><script type="math/tex; mode=display">
\hat{\sigma}_{k}^{2}=\frac{\sum_{i=1}^{m} \gamma_{ik} (x_{i}-\mu_{k})^{2}}{\sum_{i=1}^{m} \gamma_{ik}}  --- m个样本的方差加权平均</script><ul>
<li><p>（4）重复2-3步，直至收敛。</p>
<blockquote>
<p>注意，EM算法通过迭代的方式估计GMM模型的参数，得到的是<strong>局部最优解</strong>而不是全局最优。</p>
</blockquote>
</li>
</ul>
<p><strong>在迭代收敛后，遍历所有的样本，对于每个样本 $x_{i}$，计算它在各个高斯分布中的概率，将样本划分到概率最大的高斯分布中</strong>（每个高斯分布都相当于是一个簇类，因此可以理解为是将每个样本划分到相应的类别中，<strong>不过实际上是给出属于每个类别的概率而非属于某个类别）。</strong></p>
<p><strong>k-means和GMM的区别：</strong></p>
<ul>
<li><p>k-means算法是非概率模型，而GMM是概率模型</p>
<blockquote>
<p>k-means算法基于欧氏距离的度量方式将样本划分到与它距离最小的类，而GMM则是计算各个高斯分布生成样本的概率，将样本划分到取得最大概率的高斯分布中</p>
</blockquote>
</li>
<li><p>两者计算的参数不一样</p>
<blockquote>
<p>k-means计算的是簇类的均值，GMM计算的是高斯分布的参数（均值，方差和高斯混合系数）</p>
</blockquote>
</li>
<li><p>k-means是硬聚类，要么属于这一类要么属于那一类；而GMM算法是软聚类，给出的是属于某些类别的概率。</p>
</li>
<li><p>GMM每一步迭代的计算量比k-means要大。</p>
</li>
</ul>
<p><strong>k-means和GMM的区别：</strong></p>
<ul>
<li>都是聚类算法</li>
<li>都需要指定K值，且都受初始值的影响。k-means初始化k个聚类中心，GMM初始化k个高斯分布。</li>
<li>都是通过迭代的方式求解，而且都是局部最优解。k-means的求解过程其实也可以用EM算法的E步和M步来理解。</li>
</ul>
<h4 id="支持向量机（SVM）"><a href="#支持向量机（SVM）" class="headerlink" title="支持向量机（SVM）"></a>支持向量机（SVM）</h4><h5 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h5><p><strong>支持向量机（support vector machine）SVM</strong>：就是有监督学习的二分类分类模型，他的基本模型是定义在特征空间上的间隔最大的线性分类器，SVM的学习策略就是间隔最大化。</p>
<blockquote>
<p>支持向量机（英语：support vector machine，常简称为SVM，又名支持向量网络）是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。给定一组训练实例，每个训练实例被标记为属于两个类别中的一个或另一个，SVM训练算法创建一个将新的实例分配给两个类别之一的模型，使其成为非概率二元线性分类器。SVM模型是将实例表示为空间中的点，这样映射就使得单独类别的实例被尽可能宽的明显的间隔分开。然后，将新的实例映射到同一空间，并基于它们落在间隔的哪一侧来预测所属类别。</p>
</blockquote>
<p><strong>直观理解</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230917/9.png" style="zoom:67%;" /></p>
<p>图中有分别属于两类的一些二维数据点和三条直线。如果三条直线分别代表三个分类器的话，请问哪一个分类器比较好？</p>
<p>我们凭直观感受应该觉得答案是H3。首先H1不能把类别分开，这个分类器肯定是不行的；H2可以，但分割线与最近的数据点<strong>只有很小的间隔</strong>，如果测试数据有一些噪声的话可能就会被H2错误分类(即对噪声敏感、泛化能力弱)。<strong>H3以较大间隔</strong>将它们分开，这样就能容忍测试数据的一些噪声而正确分类，是一个泛化能力不错的分类器。</p>
<p>对于支持向量机来说，数据点若是p维向量，我们用p−1维的<strong>超平面</strong>来分开这些点。但是可能有许多超平面可以把数据分类。最佳超平面的一个合理选择就是以最大间隔把两个类分开的超平面。因此，<strong>SVM选择能够使离超平面最近的数据点到超平面距离最大的超平面。</strong></p>
<p>以上介绍的SVM只能解决线性可分的问题，为了解决更加复杂的问题，支持向量机学习方法有一些由简至繁的模型:</p>
<ul>
<li><p>线性可分SVM</p>
<blockquote>
<p>当训练数据线性可分时，通过硬间隔(hard margin，什么是硬、软间隔下面会讲)最大化可以学习得到一个线性分类器，即硬间隔SVM，如上图的的H3。</p>
</blockquote>
</li>
<li><p>线性SVM</p>
<blockquote>
<p>当训练数据不能线性可分但是可以近似线性可分时，通过软间隔(soft margin)最大化也可以学习到一个线性分类器，即软间隔SVM。</p>
</blockquote>
</li>
<li><p>非线性SVM</p>
<blockquote>
<p>当训练数据线性不可分时，通过使用核技巧(kernel trick)和软间隔最大化，可以学习到一个非线性SVM。</p>
</blockquote>
</li>
</ul>
<h5 id="线性可分SVM-硬间隔"><a href="#线性可分SVM-硬间隔" class="headerlink" title="线性可分SVM-硬间隔"></a>线性可分SVM-硬间隔</h5><p>如下形式的线性可分的训练数据集</p>
<script type="math/tex; mode=display">
(X_1,y_1), (X_2,y_2),....(X_i,y_i)</script><p>其中 $X_i \in R^d$ 是一个含有d个元素的列向量，$y_i$ 是标量，$y_i \in \{ -1, 1\}$，$y_i=1$ 时表示$X_i$属于正类别，反之亦然。</p>
<blockquote>
<p>注：$X$, $X_i$, $W$ 等都是（列）向量</p>
</blockquote>
<p><strong>感知机的目标</strong>: 找到一个超平面使其能正确地将每个样本正确分类。感知机使用误分类最小的方法求得超平面，不过此时解有无穷多个 (例如图1.1的H2和H3以及它俩的任意线性组合)。<strong>而线性可分支持向量机利用间隔最大化求最优分离超平面，这时解是唯一的。</strong></p>
<p>假设超平面$(W,b)$ 能够将训练样本正确分类，对于$(X_i,y_i)$ ,若 $y_i=+1$，则有 $X_{i}^{T} W+b \geq0$, ,若 $y_i=-1$，则有 $X_{i}^{T} W+b \leq 0$， 令：</p>
<script type="math/tex; mode=display">
X_{i}^{T} W+b \geq+1, y_{i}=+1</script><script type="math/tex; mode=display">
X_{i}^{T} W+b \leq-1, y_{i}=-1 \tag{2.2.1}</script><h6 id="超平面与间隔"><a href="#超平面与间隔" class="headerlink" title="超平面与间隔"></a><strong>超平面与间隔</strong></h6><p>一个超平面由法向量 $W$ 和截距 $b$ 决定，其方程如下，</p>
<script type="math/tex; mode=display">
X^TW+b=0 \tag{2.2.2}</script><p>其中法向量决定了超平面的方向，截距决定了超平面与远点的距离。我们规定<strong>法向量指向的一侧为正类,另一侧为负类</strong>。下图画出了三个平行的超平面，法方向取左上方向。</p>
<blockquote>
<p>$X$ 和 $W$ 都是列向量，$X^TW$ 会得到二者的点积是一个标量</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230917/10.jpg" style="zoom:33%;" /></p>
<p>为了找到最大间隔超平面，我们可以先选择分离两类数据的两个平行超平面，使得它们之间的距离尽可能大。**在这两个超平面范围内的区域称为“间隔(margin)”，最大间隔超平面是位于它们正中间的超平面。这个过程如上图所示。</p>
<h6 id="间隔最大化"><a href="#间隔最大化" class="headerlink" title="间隔最大化"></a><strong>间隔最大化</strong></h6><p>将高数里面求两条平行直接的距离公式推广到高维中可以求得上图中的<strong>间隔(margin)</strong>的  为</p>
<script type="math/tex; mode=display">
margin = \rho = \frac{2}{||W||} \tag{2.2.3}</script><p>目标为 $\rho$ 最大，等价于 $\rho^2$ 最大</p>
<script type="math/tex; mode=display">
\max _{W, b} \rho \Longleftrightarrow \max _{W, b} \rho^{2} \Longleftrightarrow \min _{W, b} \frac{1}{2}\|W\|^{2} \tag{2.2.4}</script><p>同时别忘记了约束条件：</p>
<script type="math/tex; mode=display">
X_{i}^{T} W+b \geq+1, y_{i}=+1</script><script type="math/tex; mode=display">
X_{i}^{T} W+b \leq-1, y_{i}=-1 \tag{2.2.5}</script><p>总结一下，间隔最大化问题的数学表达就是：</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\min _{W, b} J(W)=\min _{W, b} \frac{1}{2}\|W\|^{2} 
\end{array}</script><script type="math/tex; mode=display">
\text { s.t. } \quad y_{i}\left(X_{i}^{T} W+b\right) \geq 1, i=1,2, \ldots n . \tag{2.2.6}</script><p>这就是支持向量机的基本型，下面就是求解过程。</p>
<h6 id="支持向量"><a href="#支持向量" class="headerlink" title="支持向量"></a>支持向量</h6><p>在线性可分的情况下，训练数据集的样本点中与分离超平面距离最近的数据点称为支持向量(support vector)，支持向量是使 式（2.5）中的约束条件取等的点，即满足：</p>
<script type="math/tex; mode=display">
y_i((X_i^TW = b) =1</script><p>的点，也就是在直线 $X_{i}^{T} W+b= +1$ 或者  $X_{i}^{T} W+b= -1$ 的点，如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230917/11.jpg" alt=""></p>
<p><strong>在决定最佳超平面时只有支持向量起作用，而其他数据点并不起作用 </strong>(具体推导见后面)。如果移动非支持向量，甚至删除非支持向量都不会对最优超平面产生任何影响。也即支持向量对模型起着决定性的作用，这也是“支持向量机”名称的由来。</p>
<h6 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h6><p>如何求解？</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\min _{W, b} J(W)=\min _{W, b} \frac{1}{2}\|W\|^{2} 
\end{array}</script><script type="math/tex; mode=display">
\text { s.t. } \quad y_{i}\left(X_{i}^{T} W+b\right) \geq 1, i=1,2, \ldots n . \tag{2.4.1}</script><p>该公式本身是一个凸二次规划问题，虽然可以直接用现成的优化计算包求解，但是不够高效。定义该公式所述问题为<strong>原始问题</strong>，我们可以拉格朗日乘子法构造拉格朗日函数再通过求解其<strong>对偶问题</strong>得到原始问题的最优解，转换为对偶问题来求解的原因是：</p>
<ul>
<li>对偶问题更易求解，由下文知对偶问题只需优化一个变量 $\alpha$ 且约束条件更简单，更加高效；</li>
<li>能更加自然地引入<strong>核函数</strong>，进而推广到非线性问题。</li>
</ul>
<p>首先需要构建拉格朗日函数，为此引进拉格朗日乘子 $\alpha_i \geq 0, i=1,2,..,n $，则该问题的拉格朗日函数为：</p>
<script type="math/tex; mode=display">
L(W, b, \alpha)=\frac{1}{2}\|W\|^{2} + \sum_{i=1}^{n} \alpha_{i}\left[ 1- y_{i}\left(X_{i}^{T} W+b\right)\right] \tag{2.4.2}</script><p>因此，给定$(W,b)$ ，若不满足式(2.4.1) 的约束条件，那么：</p>
<script type="math/tex; mode=display">
\max _{\alpha} L(W, b, \alpha)=+\infty \tag{2.4.3}</script><p>否则，若满足式(2.4.1) 的约束条件，那么：</p>
<script type="math/tex; mode=display">
\max _{\alpha} L(W, b, \alpha)=J(W)=\frac{1}{2}\|W\|^{2} \tag{2.4.4}</script><p>结合式(2.4.3) 和式(2.4.4)，优化问题为：</p>
<script type="math/tex; mode=display">
\min _{W，b}\max _{\alpha} L(W, b, \alpha) \tag{2.4.5}</script><p>这与支持向量机的基本型式(2.4.1) 所述问题是完全等价的。</p>
<p>根据拉格朗日对偶性，式(2.4.1)所述的原始问题的对偶问题是：</p>
<script type="math/tex; mode=display">
\max _{\alpha}\min _{W，b} L(W, b, \alpha) \tag{2.4.6}</script><p><strong>为了求得对偶问题的解，需要先求得 $L(W, b, \alpha)$ 对 $W$ 和 $b$ 的极小再求对α的极大。</strong></p>
<p>(1) 求 $\min _{W，b} L(W, b, \alpha)$ ：求拉格朗日函数对 $W$ 和 $b$ 的偏导。并且偏导等于0，有</p>
<script type="math/tex; mode=display">
\nabla_{W} L(W, b, \alpha)=W-\sum_{i=1}^{n} \alpha_{i} y_{i} X_{i}=0 \Longrightarrow W=\sum_{i=1}^{n} \alpha_{i} y_{i} X_{i} \tag{2.4.7}</script><script type="math/tex; mode=display">
\\
\nabla_{b} L(W, b, \alpha)=-\sum_{i=1}^{n} \alpha_{i} y_{i}=0 \Longrightarrow \sum_{i=1}^{n} \alpha_{i} y_{i}=0 \tag{2.4.8}</script><p>将上面两个式代入 $L(W, b, \alpha)$, 可将其中的 $W$ 和 $b$ 消去，，</p>
<script type="math/tex; mode=display">
\begin{array}{l}
L(\mathbf{w}, b, \boldsymbol{\alpha})=\frac{1}{2}\|\mathbf{w}\|^{2}-\sum_{i=1}^{n} \alpha_{i}\left[y_{i}\left(\mathbf{x}_{i}^{T} \mathbf{w}+b\right)-1\right] \\
=\frac{1}{2} \sum_{i=1}^{n} \alpha_{i} y_{i} \mathbf{x}_{i}^{T} \sum_{j=1}^{n} \alpha_{j} y_{j} \mathbf{x}_{j}-\sum_{i=1}^{n} \alpha_{i} y_{i} \mathbf{x}_{i}^{T} \sum_{j=1}^{n} \alpha_{j} y_{j} \mathbf{x}_{j}-b \sum_{i=1}^{n} \alpha_{i} y_{i}+\sum_{i=1}^{n} \alpha_{i} \\
=\sum_{i=1}^{n} \alpha_{i}-\frac{1}{2} \sum_{i=1}^{n} \alpha_{i} y_{i} \mathbf{x}_{i}^{T} \sum_{j=1}^{n} \alpha_{j} y_{j} \mathbf{x}_{j}=\sum_{i=1}^{n} \alpha_{i}-\frac{1}{2} \sum_{i, j=1}^{n} y_{i} y_{j} \alpha_{j} \alpha_{j} \mathbf{x}_{j}^{T} \mathbf{x}_{i}
\end{array} \tag{2.4.9}</script><p>所以：</p>
<script type="math/tex; mode=display">
\min _{W，b} L(W, b, \alpha) = \sum_{i=1}^{n} \alpha_{i}-\frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} y_{i} y_{j} \alpha_{i} \alpha_{j} \mathbf{x}_{j}^{T} \mathbf{x}_{i} \tag{2.4.10}</script><p>（2）对 $\min _{W，b} L(W, b, \alpha)$  对 $\alpha$ 的极大：就得到原始问题的对偶问题的最优化。</p>
<script type="math/tex; mode=display">
\max _{\alpha}\min _{W，b} L(W, b, \alpha)  = \max _{\alpha} \sum_{i=1}^{n} \alpha_{i}-\frac{1}{2} \sum_{i=1}^{n} \sum_{i=1}^{n} y_{i} y_{j} \alpha_{i} \alpha_{j} \mathbf{x}_{j}^{T} \mathbf{x}_{i}</script><script type="math/tex; mode=display">
s.t. \quad \sum_{i=1}^{n} \alpha_{i} y_{i}=0,</script><script type="math/tex; mode=display">
\quad \alpha_i \geq 0, i=1,2,..,n  \tag{2.4.11}</script><p>（3）如何求解优化问题式 (4.11) 的最优解 $\hat{\alpha}$ ，这是一个二次规划问题，，有现成的通用算法求解。</p>
<blockquote>
<p>事实上通用的求解二次规划问题的算法的复杂度正比于训练数据样本数，所以在实际应用中需要寻求更加高效的算法，例如序列最小优化(Sequential Minimal Optimiation, SMO)算法。</p>
</blockquote>
<p>（4）假设，我们求得了式  (2.4.11) 的最优解 $\hat{\alpha}$ ，则可以根据式(2.4.7) 求得最优 $\hat{W}$,</p>
<script type="math/tex; mode=display">
\hat{W} = \sum_{i=1}^{n} \hat{\alpha_{i}} y_{i} X_{i} \tag{2.4.12}</script><p>因为至少存在一个 $\hat{\alpha_j} &gt; 0$，若不存在$(\alpha_i=0)$,则 $\hat{W} = 0$,得到 $margin = \frac{2}{||W||} = +\infty$,（显然不行）。再根据原始问题式(4.1)中是有不等式越苏的，因此上述过程需满足KKT(Karush-Kuhn-Tucker)条件，即要求：</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
\text { 乘子非负: } \alpha_{i} \geq 0(i=1,2, \ldots n . \text { 下同 }) \\
\text { 约束条件: } y_{i}\left(X_{i}^{T} W+b\right)-1 \geq 0 \\
\text { 互补条件 }: \alpha_{i}\left(y_{i}\left(X_{i}^{T} W+b\right)-1\right)=0
\end{array}\right.  \tag{2.4.13}</script><p>所以至少存在一个j，使得 $y_i(X_{i}^{T} \hat{W}+\hat{b}) - 1=0$，即可以求得最优的 $\hat{b}$:</p>
<script type="math/tex; mode=display">
\hat{b}=\frac{1}{y_{j}}-X_{j}^{T} \hat{W} 
= y_{j}-X_{j}^{T} \hat{W} 
= y_{j}-\sum_{i=1}^{n} \hat{\alpha}_{i} y_{i} X_{j}^{T} X_{i}  \tag{2.4.14}</script><p>（5）至此，我们求得了整个线性可分SVM的解，求得的分离超平面为：</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{n} \hat{\alpha_{i}} y_{i} X^T X_{i} + \hat{b} = 0  \tag{2.4.15}</script><p>支持向量和非支持向量：<strong>最优超平面只与支持向量有关而与非支持向量无关。</strong></p>
<p>再来分析KKT条件里的互补条件，对于任意样本 $(X_i, y_i)$ ，总会有 $\alpha_i=0$ 或者 $y_if(X_i) = y_i(X_i^T\hat{W} + b) = 1$。则有若 $\alpha_i=0$ ，此样本点不是支持向量，对模型没有任何作用；若 $\alpha_i&gt;0$ ，此样本点位于最大间隔边界上，是一个支持向量，如下图所示。</p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230917/15.jpg" style="zoom:33%;" /></p>
<p>则分类的决策函数为</p>
<script type="math/tex; mode=display">
f(X) = sign(\sum_{i=1}^{n} \hat{\alpha_{i}} y_{i} X^T X_{i} + \hat{b}) \tag{2.4.16}</script><h5 id="线性SVM-软间隔"><a href="#线性SVM-软间隔" class="headerlink" title="线性SVM-软间隔"></a>线性SVM-软间隔</h5><p>在前面的讨论中，我们一直假定训练数据是严格线性可分的，即存在一个超平面能完全将两类数据分开。但是现实任务这个假设往往不成立，例如下图所示的数据。</p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230917/13.jpg" style="zoom:50%;" /></p>
<h6 id="软间隔最大化"><a href="#软间隔最大化" class="headerlink" title="软间隔最大化"></a>软间隔最大化</h6><p>解决该问题的一个办法是允许SVM在少量样本上出错，即将之前的硬间隔最大化条件放宽一点，为此引入“软间隔(soft margin)”的概念。即允许少量样本不满足约束：</p>
<script type="math/tex; mode=display">
y_i((X_i^TW = b) \geq 1  \tag{3.1.1}</script><p>为了使不满足上述条件的样本点尽可能少，我们需要在优化的目标函数(2.2.4)里面新增一个对这些点的惩罚项。最常用的是hinge损失:</p>
<script type="math/tex; mode=display">
l_{hinge}(z) = max(0, 1-z) \tag{3.1.2}</script><p>即若样本点满足约束条件损失就是0, 否则损失就是 $1-z$, 则优化目标(2.2.4)变成:</p>
<script type="math/tex; mode=display">
\min _{W, b} \frac{1}{2}\|W\|^{2} + C \sum_{i=1}^{n}max(0, 1-y_i(X^TW+b))  \tag{3.1.3}</script><p><strong>其中 $C&gt;0$ 称为惩罚参数</strong>，C越小时对误分类惩罚越小，越大时对误分类惩罚越大，当C取正无穷时就变成了硬间隔优化。实际应用时我们要合理选取C，C越小越容易欠拟合，C越大越容易过拟合。</p>
<p>如果我们引入 <strong>松弛变量</strong> $\xi_{i} \geq 0$，那种优化目标可以重写为：</p>
<script type="math/tex; mode=display">
\min _{W, b} \frac{1}{2}\|W\|^{2} + C \sum_{i=1}^{n} \xi_{i}</script><script type="math/tex; mode=display">
\text { s.t. } \quad y_{i}\left(X_{i}^{T} W+b\right) \ge 1-\xi_{i}</script><script type="math/tex; mode=display">
\xi_{i} \ge 0 ,i=1,2,...n.  \tag{3.1.4}</script><p><strong>上式所述问题即软间隔支持向量机。</strong></p>
<h6 id="对偶问题-1"><a href="#对偶问题-1" class="headerlink" title="对偶问题"></a>对偶问题</h6><p>式(3.1.4)表示的软间隔支持向量机依然是一个凸二次规划问题，和硬间隔支持向量机类似，我们可以通过拉格朗日乘子法将其转换为对偶问题进行求解。 式(3.1.4)对应的拉格朗日函数为：</p>
<script type="math/tex; mode=display">
L(W, b, \xi, \alpha, \beta)=\frac{1}{2}\|W\|^{2}+C \sum_{i=1}^{n} \xi_{i}-\sum_{i=1}^{n} \alpha_{i}\left[y_{i}\left(X_{i}^{T} W+b\right)-1+\xi_{i}\right]-\sum_{i=1}^{n} \beta_{i} \xi_{i} \tag{3.2.1}</script><p>类似上面，为了求得对偶问题的解，我们需要先求得 $L(W, b, \xi, \alpha, \beta)$ 对 $( W,b, \xi)$ 的极小再求对 $(\alpha, \beta )$ 的极大。</p>
<p>（1）求 $\min _{W，b， \xi} L(W, b, \xi, \alpha, \beta)$：将 $ L(W, b, \xi, \alpha, \beta) $ 分别对  $( W,b, \xi)$ 求偏导，并且偏导为0，得到：</p>
<script type="math/tex; mode=display">
W=\sum_{i=1}^{n} \alpha_{i} y_{i} X_{i}</script><script type="math/tex; mode=display">
\sum_{i=1}^{n} \alpha_{i} y_{i}=0</script><script type="math/tex; mode=display">
C = \alpha_i + \beta_i  \tag{3.2.2}</script><p>将上面两个式代入 $L(W, b, \xi, \alpha, \beta)$, 可将其中的 $W$ 和 $b$ 和 $\beta$ 消去，</p>
<script type="math/tex; mode=display">
\min _{W，b, \xi} L(W, b, \xi, \alpha, \beta) = \sum_{i=1}^{n} \alpha_{i}-\frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} y_{i} y_{j} \alpha_{i} \alpha_{j} \mathbf{x}_{j}^{T} \mathbf{x}_{i} \tag{3.2.3}</script><p>（2）对 $\min _{W，b, \xi} L(W, b, \alpha, \beta)$  对 $\alpha$ 的极大：就得到原始问题的对偶问题的最优化。</p>
<script type="math/tex; mode=display">
\max _{\alpha}\min _{W，b, \xi} L(W, b, \alpha, \beta)  = \max _{\alpha} \sum_{i=1}^{n} \alpha_{i}-\frac{1}{2} \sum_{i=1}^{n} \sum_{i=1}^{n} y_{i} y_{j} \alpha_{i} \alpha_{j} \mathbf{x}_{j}^{T} \mathbf{x}_{i}</script><script type="math/tex; mode=display">
s.t. \quad \sum_{i=1}^{n} \alpha_{i} y_{i}=0,</script><script type="math/tex; mode=display">
\quad 0 \leq \alpha_i \leq C, i=1,2,..,n  \tag{3.2.4}</script><p>（3）类似上面，可以利用现成的通用算法，例如SMO算法 ，求式(3.2.4)。</p>
<p>（4）KTT条件：</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
\text { 乘子非负: } \alpha_{i} \geq 0, \beta_{i} \geq 0(i=1,2, \ldots n . \text { 下同 }) \\
\text { 约束条件: } y_{i}\left(X_{i}^{T} W+b\right)-1 \geq \xi_i \\
\text { 互补条件 }: \alpha_{i}\left[y_{i}\left(X_{i}^{T} W+b\right)-1 + \xi_i\right]=0, \beta_i\xi_i=0
\end{array}\right.  \tag{3.2.5}</script><p>对于任意样本 $(X_i,y_i)$，若 $\alpha_i=0$，此样本点不是支持向量，该样本对模型没有任何的作用；若 $\alpha_i&gt;0$，此样本是一个支持向量。</p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230917/14.jpg" style="zoom:33%;" /></p>
<p>因此，<strong>最优超平面只与支持向量有关而与非支持向量无关。</strong></p>
<h6 id="惩罚参数C"><a href="#惩罚参数C" class="headerlink" title="惩罚参数C"></a>惩罚参数C</h6><p>对于不同惩罚参数C，SVM结果如下图所示</p>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230917/16.jpg" alt=""></p>
<p>再来看看我们的原始目标函数:</p>
<script type="math/tex; mode=display">
\min _{W, b} \frac{1}{2}\|W\|^{2} + C \sum_{i=1}^{n} \xi_{i} \tag{3.2.6}</script><p>对于更加一般化的问题，可将上述式子抽象成：</p>
<script type="math/tex; mode=display">
\min _{f} \Omega(f)+C \sum_{i=1}^{n} l\left(f\left(x_{i}\right), y_{i}\right)  \tag{3.2.7}</script><p>前一项可以理解为“结构风险(structural risk)”，用来描述所求模型的某些性质(SVM就是要求间隔最大)；第二项称为“经验风险(empirical risk)”，用来描述模型与训练数据的契合程度(即误差)。而参数C就是用于对二者的折中,即我们一方面要求模型要满足某种性质另一方面又想使模型与训练数据很契合。</p>
<p><strong>从正则化角度来讲，Ω(f)称为正则化项，C称为惩罚参数，C越大即对误分类的惩罚越大(要求模型对训练模型更契合)，这可能会存在过拟合；C越小即相对更加看重正则化项，此时可能存在欠拟合。</strong></p>
<h5 id="非线性SVM-核技巧"><a href="#非线性SVM-核技巧" class="headerlink" title="非线性SVM-核技巧"></a>非线性SVM-核技巧</h5><p>前面介绍的都是线性问题，但是我们经常会遇到非线性的问题(例如异或问题)，此时就需要用到<strong>核技巧(kernel trick)将线性支持向量机推广到非线性支持向量机</strong>。需要注意的是，不仅仅是SVM，很多线性模型都可以用核技巧推广到非线性模型，例如核线性判别分析(KLDA)。</p>
<p>为了使不满足上述条件的样本点尽可能少，我们需要在优化的目标函数(2.2.2)里面新增一个对这些点的惩罚项。最常用的是hinge损失:</p>
<h6 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h6><p>核技巧的基本思路分为两步:</p>
<ul>
<li>使用一个变换将原空间的数据映射到新空间(例如更高维甚至无穷维的空间)；</li>
<li>然后在新空间里用线性方法从训练数据中学习得到模型。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230917/12.jpg" style="zoom:50%;" /></p>
<p>和函数的定义：</p>
<blockquote>
<p>设X是输入空间(欧式空间$R^n$的子集或离散集合)，又设H是特征空间(希尔伯特空间)，如果存在一个X到H的映射 ϕ(x):X→H 使得对所有 x,z∈X，函数 K(x,z) 满足条 件K(x,z)=ϕ(x)⋅ϕ(z) 则称 K(x,z) 为核函数，ϕ(x)为映射函数，式中 ϕ(x)⋅ϕ(z) 为 ϕ(x)和ϕ(z) 的內积。</p>
</blockquote>
<p>通常，直接计算 K(x,z) 比较容易而通过 ϕ(x)和ϕ(z) 计算 K(x,z) 并不容易。而幸运的是，在线性支持向量机的对偶问题中，无论是目标函数还是决策函数都只涉及到输入样本与样本之间的內积，因此我们不需要显式地定义映射 ϕ(x) 是什么，而只需事先定义核函数 K(x,z) 即可。也就是说，在核函数 K(x,z) 给定的情况下，可以利用解线性问题的方法求解非线性问题的支持向量机，此过程是隐式地在特征空间中进行的。</p>
<h6 id="正定核"><a href="#正定核" class="headerlink" title="正定核"></a>正定核</h6><p>由上面的介绍可知，我们只需要定义核函数就可以了。但是如何不通过映射 ϕ(x) 判断给定的一个函数 K(x,z) 是不是核函数呢？或者说，K(x,z) 需要满足什么条件才是一个核函数？</p>
<p>通常所说的核函数就是正定核函数。常用的核函数：</p>
<ul>
<li><p>多项式核函数：</p>
<script type="math/tex; mode=display">
K(x, z) = (x \cdot z + 1)^p</script></li>
<li><p>高斯核函数：</p>
<script type="math/tex; mode=display">
K(x, z) = exp(-\frac{||x-z||^2}{2 \sigma})</script></li>
</ul>
<h6 id="非线性支持向量机"><a href="#非线性支持向量机" class="headerlink" title="非线性支持向量机"></a>非线性支持向量机</h6><p>利用核技巧可以很简单地把线性支持向量机扩展到非线性支持向量机，只需将线性支持向量机中的內积换成核函数即可。下面简述非线性支持向量机学习算法。</p>
<ul>
<li><p>首先选取适当的核函数 $K(x,z)$ 和适当的参数 $C$，构造最优化问题：</p>
<script type="math/tex; mode=display">
\max _{\alpha}\min _{W，b} L(W, b, \alpha)  = \max _{\alpha} \sum_{i=1}^{n} \alpha_{i}-\frac{1}{2} \sum_{i, j=1}^{n} y_{i} y_{j} \alpha_{j} \alpha_{j} K(X_i,K_j)</script><script type="math/tex; mode=display">
s.t. \quad \sum_{i=1}^{n} \alpha_{i} y_{i}=0,</script><script type="math/tex; mode=display">
\quad 0 \leq \alpha_i \leq C, i=1,2,..,n</script></li>
</ul>
<ul>
<li>构造决策函数：<script type="math/tex; mode=display">
f(X) = sign(\sum_{i=1}^{n} \hat{\alpha_{i}} y_{i} K(X_i,K_j) + \hat{b})</script></li>
</ul>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul>
<li><p>简单介绍SVM？</p>
<p>支持向量机SVM是一种二类分类模型。它的基本模型是定义在特征空间中的间隔最大的线性分类器。学习的目标就是在特征空间内找到一个分离超平面，能够将实例分到不同的类。</p>
<blockquote>
<p>从分类平面，到求两类间的最大间隔，到转化为求间隔分之一，等优化问题，然后就是优化问题的解决办法，首先是用拉格拉日乘子把约束优化转化为无约束优化，对各个变量求导令其为零，得到的式子带入拉格朗日式子从而转化为对偶问题，最后再利用SMO（序列最小优化）来解决这个对偶问题。</p>
</blockquote>
<ul>
<li>当训练样本线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机；</li>
<li>当训练数据近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机；</li>
<li>当训练数据线性不可分时，通过使用核技巧及软间隔最大化，学习非线性支持向量机。</li>
</ul>
</li>
</ul>
<ul>
<li><p>什么是支持向量？</p>
<p>在线性可分的情况下，训练数据集的样本点中与分离超平面距离最近的样本点的实例称为支持向量（support vector）。</p>
</li>
</ul>
<ul>
<li><p>SVM为什么采用间隔最大化？</p>
<p>当训练数据线性可分时，存在<strong>无穷个分离超平面可以将两类数据正确分开</strong>。感知机利用误分类最小策略，求得分离超平面，不过此时的解有无穷多个。线性可分支持向量机利用间<strong>隔最大化求得最优分离超平面，这时，解是唯一的</strong>。另一方面，此时的分隔超平面所产生的分类结果是最鲁棒的，对未知实例的泛化能力最强。可以借此机会阐述一下几何间隔以及函数间隔的关系</p>
</li>
</ul>
<ul>
<li><p>为什么要将求解问题SVM的原始问题转换为其对偶问题？</p>
<ul>
<li><p><strong>对偶问题往往更易求解</strong>，当我们寻找约束存在时的最优点的时候，约束的存在虽然减小了需要搜寻的范围，但是却使问题变得更加复杂。为了使问题变得易于处理，我们的方法是把目标函数和约束全部融入一个新的函数，即拉格朗日函数，再通过这个函数来寻找最优点。</p>
</li>
<li><p><strong>可以自然引入核函数，进而推广到非线性分类问题。</strong></p>
</li>
<li><strong>求解更高效，改变了问题的复杂度</strong>，由求特征向量w转化为求比例系数a，在原始问题下，求解的复杂度与样本的维度有关，即w的维度。在对偶问题下，只与样本数量有关。因为只用求解alpha系数，而alpha系数只有支持向量才非0，其他全部为0。</li>
</ul>
</li>
</ul>
<ul>
<li><p>为什么SVM要引入核函数？</p>
<p><strong>当样本在原始空间线性不可分时，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分</strong>。而引入这样的映射后，所要求解的对偶问题的求解中，无需求解真正的映射函数，而只需要知道其核函数。核函数的定义：K(x,y)=&lt;ϕ(x),ϕ(y)&gt;，即在特征空间的内积等于它们在原始样本空间中通过核函数 K 计算的结果。一方面数据变成了高维空间中线性可分的数据，另一方面不需要求解具体的映射函数，只需要给定具体的核函数即可，这样使得求解的难度大大降低。</p>
</li>
</ul>
<ul>
<li><p>为什么SVM对数据确实敏感？</p>
<p>缺失数据是指缺失某些特征数据，向量数据不完整。SVM没有处理缺失值的策略（决策树有）。而SVM希望样本在特征空间中线性可分，所以特征空间的好坏对SVM的性能很重要。缺失特征数据将影响训练结果的好坏。</p>
</li>
</ul>
<p><strong>支持向量机的优点:</strong></p>
<ol>
<li>由于SVM是一个凸优化问题，所以求得的解一定是全局最优而不是局部最优。</li>
<li>不仅适用于线性线性问题还适用于非线性问题(用核技巧)。</li>
<li>拥有高维样本空间的数据也能用SVM，这是因为数据集的复杂度只取决于支持向量而不是数据集的维度，这在某种意义上避免了“维数灾难”。</li>
<li>理论基础比较完善(例如神经网络就更像一个黑盒子)。</li>
<li>SVM无需依赖所有样本， 只依赖支持向量</li>
</ol>
<p><strong>支持向量机的缺点是:</strong></p>
<ol>
<li>二次规划问题求解将涉及m阶矩阵的计算(m为样本的个数), 因此SVM不适用于超大数据集。(SMO算法可以缓解这个问题)</li>
<li>只适用于二分类问题。(SVM的推广SVR也适用于回归问题；可以通过多个SVM的组合来解决多分类问题)</li>
<li>SVM对缺失值敏感</li>
<li>如果特征维度远大于样本个数，SVM变现一般</li>
<li>SNM在样本巨大且使用核函数时计算量很大。</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">sevenboy</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://sevenboy.online/%E4%BA%BA%E5%B7%A5%E5%8F%AA%E8%83%BD/Prior-Knowledge/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/">https://sevenboy.online/%E4%BA%BA%E5%B7%A5%E5%8F%AA%E8%83%BD/Prior-Knowledge/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://sevenboy.online" target="_blank">sevenboy</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E5%8F%AA%E8%83%BD/">人工只能</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/machine-learning/">machine learning</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/image.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/%E4%BA%BA%E5%B7%A5%E5%8F%AA%E8%83%BD/Prior-Knowledge/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/image1.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">图像处理算法总结</div></div></a></div><div class="next-post pull-right"><a href="/%E4%BA%BA%E5%B7%A5%E5%8F%AA%E8%83%BD/Prior-Knowledge/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230810/image.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">对比学习相关总结</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/人工只能/papers-ICCV/Few-shot-Semantic-Segmentation-with-Classifier-Weight-Transformer/" title="simpler-is-better:Few-shot_Semantic_Segmentation_with_Classifier_Weight_Transformer"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20211108/9.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-11-08</div><div class="title">simpler-is-better:Few-shot_Semantic_Segmentation_with_Classifier_Weight_Transformer</div></div></a></div><div><a href="/人工只能/Prior-Knowledge/Loss-in-Deep-Learning/" title="Loss_in_Deep_Learning"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230422/1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-22</div><div class="title">Loss_in_Deep_Learning</div></div></a></div><div><a href="/人工只能/Prior-Knowledge/Metric-in-Semantic-Segmentation/" title="Metric_in_Semantic_Segmentation"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230326/head.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-25</div><div class="title">Metric_in_Semantic_Segmentation</div></div></a></div><div><a href="/人工只能/papers-CVPR/SETR-Rethinking-Semantic-Segmentation-from-a-Sequence-to-Sequence-Perspective-with-Transformers/" title="SETR:Rethinking_Semantic_Segmentation_from_a_Sequence-to-Sequence_Perspective_with_Transformers"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20211203/2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-03</div><div class="title">SETR:Rethinking_Semantic_Segmentation_from_a_Sequence-to-Sequence_Perspective_with_Transformers</div></div></a></div><div><a href="/人工只能/papers-ICCV/SOTR-Segmenting-Objects-with-Transformers/" title="SOTR-Segmenting-Objects-with-Transformers"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20211027/figure-1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-10-27</div><div class="title">SOTR-Segmenting-Objects-with-Transformers</div></div></a></div><div><a href="/人工只能/papers/TransFuse-Fusing-Transformers-and-CNNs-for-Medical-Image-Segmentation/" title="TransFuse:Fusing_Transformers_and_CNNs_for_Medical_Image_Segmentation"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiewende/blog_img/20211212/2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-03</div><div class="title">TransFuse:Fusing_Transformers_and_CNNs_for_Medical_Image_Segmentation</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">集成学习</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#bagging%E5%A5%97%E8%A2%8B%E6%B3%95"><span class="toc-number">1.1.</span> <span class="toc-text">bagging套袋法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#boosting%E6%8F%90%E5%8D%87%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">boosting提升法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#bagging%E5%92%8Cboosting%E5%8C%BA%E5%88%AB"><span class="toc-number">1.3.</span> <span class="toc-text">bagging和boosting区别</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#stacking%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88"><span class="toc-number">1.4.</span> <span class="toc-text">stacking模型融合</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">2.</span> <span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#ID3%E7%AE%97%E6%B3%95%EF%BC%88%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%EF%BC%89"><span class="toc-number">2.1.</span> <span class="toc-text">ID3算法（信息增益）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#C4-5%E7%AE%97%E6%B3%95%EF%BC%88%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%8E%87%EF%BC%89"><span class="toc-number">2.2.</span> <span class="toc-text">C4.5算法（信息增益率）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#CART%E7%AE%97%E6%B3%95%EF%BC%88%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B0%EF%BC%89"><span class="toc-number">2.3.</span> <span class="toc-text">CART算法（基尼系数）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E6%80%BB%E7%BB%93"><span class="toc-number">2.4.</span> <span class="toc-text">对比总结</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%EF%BC%88Bagging%EF%BC%89"><span class="toc-number">3.</span> <span class="toc-text">随机森林（Bagging）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Boosting%E7%AE%97%E6%B3%95%E4%BB%A3%E8%A1%A8"><span class="toc-number">4.</span> <span class="toc-text">Boosting算法代表</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#AdaBoost%E7%AE%97%E6%B3%95"><span class="toc-number">4.1.</span> <span class="toc-text">AdaBoost算法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#GBDT%E7%AE%97%E6%B3%95"><span class="toc-number">4.2.</span> <span class="toc-text">GBDT算法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#XGBoost%E7%AE%97%E6%B3%95"><span class="toc-number">4.3.</span> <span class="toc-text">XGBoost算法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E6%80%BB%E7%BB%93-1"><span class="toc-number">4.4.</span> <span class="toc-text">对比总结</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number">5.</span> <span class="toc-text">K-means聚类算法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#K-means%E7%AE%97%E6%B3%95"><span class="toc-number">5.1.</span> <span class="toc-text">K-means算法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#K-means-%E7%AE%97%E6%B3%95"><span class="toc-number">5.2.</span> <span class="toc-text">K-means++算法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%80%89%E5%8F%96K%E5%80%BC%EF%BC%9F"><span class="toc-number">5.3.</span> <span class="toc-text">如何选取K值？</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%89%8B%E8%82%98%E6%B3%95"><span class="toc-number">5.3.1.</span> <span class="toc-text">手肘法</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Gap-Statistic"><span class="toc-number">5.3.2.</span> <span class="toc-text">Gap Statistic</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ISODATA-%E7%AE%97%E6%B3%95"><span class="toc-number">5.4.</span> <span class="toc-text">ISODATA 算法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#K-means%E5%92%8C-KNN-%E7%AE%97%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">5.5.</span> <span class="toc-text">K-means和 KNN 算法的区别</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#K-means%E5%92%8CGMM%E7%AE%97%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">5.6.</span> <span class="toc-text">K-means和GMM算法的区别</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89"><span class="toc-number">6.</span> <span class="toc-text">支持向量机（SVM）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E8%A6%81"><span class="toc-number">6.1.</span> <span class="toc-text">概要</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86SVM-%E7%A1%AC%E9%97%B4%E9%9A%94"><span class="toc-number">6.2.</span> <span class="toc-text">线性可分SVM-硬间隔</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E8%B6%85%E5%B9%B3%E9%9D%A2%E4%B8%8E%E9%97%B4%E9%9A%94"><span class="toc-number">6.2.1.</span> <span class="toc-text">超平面与间隔</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E9%97%B4%E9%9A%94%E6%9C%80%E5%A4%A7%E5%8C%96"><span class="toc-number">6.2.2.</span> <span class="toc-text">间隔最大化</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F"><span class="toc-number">6.2.3.</span> <span class="toc-text">支持向量</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98"><span class="toc-number">6.2.4.</span> <span class="toc-text">对偶问题</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7SVM-%E8%BD%AF%E9%97%B4%E9%9A%94"><span class="toc-number">6.3.</span> <span class="toc-text">线性SVM-软间隔</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E8%BD%AF%E9%97%B4%E9%9A%94%E6%9C%80%E5%A4%A7%E5%8C%96"><span class="toc-number">6.3.1.</span> <span class="toc-text">软间隔最大化</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98-1"><span class="toc-number">6.3.2.</span> <span class="toc-text">对偶问题</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%83%A9%E7%BD%9A%E5%8F%82%E6%95%B0C"><span class="toc-number">6.3.3.</span> <span class="toc-text">惩罚参数C</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7SVM-%E6%A0%B8%E6%8A%80%E5%B7%A7"><span class="toc-number">6.4.</span> <span class="toc-text">非线性SVM-核技巧</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="toc-number">6.4.1.</span> <span class="toc-text">核函数</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%AD%A3%E5%AE%9A%E6%A0%B8"><span class="toc-number">6.4.2.</span> <span class="toc-text">正定核</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-number">6.4.3.</span> <span class="toc-text">非线性支持向量机</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">6.5.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/gh/xiewende/blog_img/20230823/image.png')"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2023 By sevenboy</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">this is a sunshine body</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script src="https://cdn.jsdelivr.net/gh/lete114/CDN/Sum/sakura.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" data-mobile="false" data-text="阳光,向上,好学,积极,热爱,奋斗,拼搏,追求,奋发" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":180,"height":330},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>